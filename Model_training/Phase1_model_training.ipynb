{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_dataset(\"coastalcph/lex_glue\", \"scotus\")\n",
    "processed_data=datasets.load_dataset(\"victorambrose11/final_preprocessed_scotus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import fasttext\n",
    "import tempfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = {\n",
    "    \"train\": dataset[\"train\"].to_pandas(),\n",
    "    \"validation\": dataset[\"validation\"].to_pandas(),\n",
    "    \"test\": dataset[\"test\"].to_pandas()\n",
    "}\n",
    "\n",
    "cleaned_data = {\n",
    "    \"train\": processed_data[\"train\"].to_pandas(),\n",
    "    \"validation\": processed_data[\"validation\"].to_pandas(),\n",
    "    \"test\": processed_data[\"test\"].to_pandas()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"micro_f1\": f1_score(y_test, y_pred, average='micro'),\n",
    "        \"macro_f1\": f1_score(y_test, y_pred, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tfidf_svm(data):\n",
    "    pipe = Pipeline([\n",
    "        (\"vec\", TfidfVectorizer(max_features=10000)),\n",
    "        (\"clf\", LinearSVC())\n",
    "    ])\n",
    "    return evaluate_model(\"TF-IDF + SVM\", pipe,\n",
    "                          data[\"train\"][\"text\"], data[\"train\"][\"label\"],\n",
    "                          data[\"test\"][\"text\"], data[\"test\"][\"label\"])\n",
    "\n",
    "def run_tfidf_logreg(data):\n",
    "    pipe = Pipeline([\n",
    "        (\"vec\", TfidfVectorizer(max_features=10000)),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    return evaluate_model(\"TF-IDF + LogReg\", pipe,\n",
    "                          data[\"train\"][\"text\"], data[\"train\"][\"label\"],\n",
    "                          data[\"test\"][\"text\"], data[\"test\"][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fasttext(data):\n",
    "    with tempfile.NamedTemporaryFile(mode='w+', delete=False) as train_file, \\\n",
    "         tempfile.NamedTemporaryFile(mode='w+', delete=False) as test_file:\n",
    "\n",
    "        for text, label in zip(data[\"train\"][\"text\"], data[\"train\"][\"label\"]):\n",
    "            train_file.write(f\"__label__{label} {text}\\n\")\n",
    "\n",
    "        for text, label in zip(data[\"test\"][\"text\"], data[\"test\"][\"label\"]):\n",
    "            test_file.write(f\"__label__{label} {text}\\n\")\n",
    "\n",
    "    model = fasttext.train_supervised(input=train_file.name, epoch=25, lr=1.0, wordNgrams=2, verbose=0)\n",
    "    preds = [int(model.predict(text)[0][0].replace(\"__label__\", \"\")) for text in data[\"test\"][\"text\"]]\n",
    "\n",
    "    os.unlink(train_file.name)\n",
    "    os.unlink(test_file.name)\n",
    "\n",
    "    return {\n",
    "        \"model\": \"fastText\",\n",
    "        \"accuracy\": accuracy_score(data[\"test\"][\"label\"], preds),\n",
    "        \"micro_f1\": f1_score(data[\"test\"][\"label\"], preds, average='micro'),\n",
    "        \"macro_f1\": f1_score(data[\"test\"][\"label\"], preds, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_word2vec_logreg(data):\n",
    "    tokenized_train = [text.split() for text in data[\"train\"][\"text\"]]\n",
    "    tokenized_test = [text.split() for text in data[\"test\"][\"text\"]]\n",
    "\n",
    "    model = Word2Vec(sentences=tokenized_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "    def embed(docs):\n",
    "        embeddings = []\n",
    "        for doc in docs:\n",
    "            vecs = [model.wv[word] for word in doc if word in model.wv]\n",
    "            if vecs:\n",
    "                embeddings.append(np.mean(vecs, axis=0))\n",
    "            else:\n",
    "                embeddings.append(np.zeros(100))\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    X_train = embed(tokenized_train)\n",
    "    X_test = embed(tokenized_test)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, data[\"train\"][\"label\"])\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"model\": \"Word2Vec + LogReg\",\n",
    "        \"accuracy\": accuracy_score(data[\"test\"][\"label\"], y_pred),\n",
    "        \"micro_f1\": f1_score(data[\"test\"][\"label\"], y_pred, average='micro'),\n",
    "        \"macro_f1\": f1_score(data[\"test\"][\"label\"], y_pred, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_original = [\n",
    "    run_tfidf_svm(original_data),\n",
    "    run_tfidf_logreg(original_data),\n",
    "    run_fasttext(original_data),\n",
    "    run_word2vec_logreg(original_data)\n",
    "]\n",
    "\n",
    "results_cleaned = [\n",
    "    run_tfidf_svm(cleaned_data),\n",
    "    run_tfidf_logreg(cleaned_data),\n",
    "    run_fasttext(cleaned_data),\n",
    "    run_word2vec_logreg(cleaned_data)\n",
    "]\n",
    "\n",
    "# Format results for display\n",
    "df_results = pd.DataFrame(results_original + results_cleaned)\n",
    "df_results[\"dataset\"] = [\"original\"] * 4 + [\"preprocessed\"] * 4\n",
    "df_results = df_results[[\"dataset\", \"model\", \"accuracy\", \"micro_f1\", \"macro_f1\"]]\n",
    "df_results\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
