{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_dataset(\"coastalcph/lex_glue\", \"scotus\")\n",
    "processed_data=datasets.load_dataset(\"victorambrose11/final_preprocessed_scotus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "import fasttext\n",
    "import tempfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = {\n",
    "    \"train\": dataset[\"train\"].to_pandas(),\n",
    "    \"validation\": dataset[\"validation\"].to_pandas(),\n",
    "    \"test\": dataset[\"test\"].to_pandas()\n",
    "}\n",
    "\n",
    "cleaned_data = {\n",
    "    \"train\": processed_data[\"train\"].to_pandas(),\n",
    "    \"validation\": processed_data[\"validation\"].to_pandas(),\n",
    "    \"test\": processed_data[\"test\"].to_pandas()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"micro_f1\": f1_score(y_test, y_pred, average='micro'),\n",
    "        \"macro_f1\": f1_score(y_test, y_pred, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tfidf_svm(data):\n",
    "    pipe = Pipeline([\n",
    "        (\"vec\", TfidfVectorizer(max_features=10000)),\n",
    "        (\"clf\", LinearSVC())\n",
    "    ])\n",
    "    return evaluate_model(\"TF-IDF + SVM\", pipe,\n",
    "                          data[\"train\"][\"text\"], data[\"train\"][\"label\"],\n",
    "                          data[\"test\"][\"text\"], data[\"test\"][\"label\"])\n",
    "\n",
    "def run_tfidf_logreg(data):\n",
    "    pipe = Pipeline([\n",
    "        (\"vec\", TfidfVectorizer(max_features=10000)),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "    return evaluate_model(\"TF-IDF + LogReg\", pipe,\n",
    "                          data[\"train\"][\"text\"], data[\"train\"][\"label\"],\n",
    "                          data[\"test\"][\"text\"], data[\"test\"][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fasttext(data):\n",
    "    with tempfile.NamedTemporaryFile(mode='w+', delete=False) as train_file, \\\n",
    "         tempfile.NamedTemporaryFile(mode='w+', delete=False) as test_file:\n",
    "\n",
    "        for text, label in zip(data[\"train\"][\"text\"], data[\"train\"][\"label\"]):\n",
    "            train_file.write(f\"__label__{label} {text}\\n\")\n",
    "\n",
    "        for text, label in zip(data[\"test\"][\"text\"], data[\"test\"][\"label\"]):\n",
    "            test_file.write(f\"__label__{label} {text}\\n\")\n",
    "\n",
    "    model = fasttext.train_supervised(input=train_file.name, epoch=25, lr=1.0, wordNgrams=2, verbose=0)\n",
    "    preds = [int(model.predict(text)[0][0].replace(\"__label__\", \"\")) for text in data[\"test\"][\"text\"]]\n",
    "\n",
    "    os.unlink(train_file.name)\n",
    "    os.unlink(test_file.name)\n",
    "\n",
    "    return {\n",
    "        \"model\": \"fastText\",\n",
    "        \"accuracy\": accuracy_score(data[\"test\"][\"label\"], preds),\n",
    "        \"micro_f1\": f1_score(data[\"test\"][\"label\"], preds, average='micro'),\n",
    "        \"macro_f1\": f1_score(data[\"test\"][\"label\"], preds, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_word2vec_logreg(data):\n",
    "    tokenized_train = [text.split() for text in data[\"train\"][\"text\"]]\n",
    "    tokenized_test = [text.split() for text in data[\"test\"][\"text\"]]\n",
    "\n",
    "    model = Word2Vec(sentences=tokenized_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "    def embed(docs):\n",
    "        embeddings = []\n",
    "        for doc in docs:\n",
    "            vecs = [model.wv[word] for word in doc if word in model.wv]\n",
    "            if vecs:\n",
    "                embeddings.append(np.mean(vecs, axis=0))\n",
    "            else:\n",
    "                embeddings.append(np.zeros(100))\n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "    X_train = embed(tokenized_train)\n",
    "    X_test = embed(tokenized_test)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, data[\"train\"][\"label\"])\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"model\": \"Word2Vec + LogReg\",\n",
    "        \"accuracy\": accuracy_score(data[\"test\"][\"label\"], y_pred),\n",
    "        \"micro_f1\": f1_score(data[\"test\"][\"label\"], y_pred, average='micro'),\n",
    "        \"macro_f1\": f1_score(data[\"test\"][\"label\"], y_pred, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>TF-IDF + SVM</td>\n",
       "      <td>0.734286</td>\n",
       "      <td>0.734286</td>\n",
       "      <td>0.622410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>TF-IDF + LogReg</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.452079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>Word2Vec + LogReg</td>\n",
       "      <td>0.603571</td>\n",
       "      <td>0.603571</td>\n",
       "      <td>0.411642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>preprocessed</td>\n",
       "      <td>TF-IDF + SVM</td>\n",
       "      <td>0.627143</td>\n",
       "      <td>0.627143</td>\n",
       "      <td>0.480467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>preprocessed</td>\n",
       "      <td>TF-IDF + LogReg</td>\n",
       "      <td>0.598571</td>\n",
       "      <td>0.598571</td>\n",
       "      <td>0.344033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>preprocessed</td>\n",
       "      <td>Word2Vec + LogReg</td>\n",
       "      <td>0.419286</td>\n",
       "      <td>0.419286</td>\n",
       "      <td>0.215896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset              model  accuracy  micro_f1  macro_f1\n",
       "0      original       TF-IDF + SVM  0.734286  0.734286  0.622410\n",
       "1      original    TF-IDF + LogReg  0.682857  0.682857  0.452079\n",
       "2      original  Word2Vec + LogReg  0.603571  0.603571  0.411642\n",
       "3  preprocessed       TF-IDF + SVM  0.627143  0.627143  0.480467\n",
       "4  preprocessed    TF-IDF + LogReg  0.598571  0.598571  0.344033\n",
       "5  preprocessed  Word2Vec + LogReg  0.419286  0.419286  0.215896"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_original = [\n",
    "    run_tfidf_svm(original_data),\n",
    "    run_tfidf_logreg(original_data),\n",
    "    run_word2vec_logreg(original_data)\n",
    "]\n",
    "\n",
    "results_cleaned = [\n",
    "    run_tfidf_svm(cleaned_data),\n",
    "    run_tfidf_logreg(cleaned_data),\n",
    "    run_word2vec_logreg(cleaned_data)\n",
    "]\n",
    "\n",
    "# Format results for display\n",
    "df_results = pd.DataFrame(results_original + results_cleaned)\n",
    "df_results[\"dataset\"] = [\"original\"] * 3 + [\"preprocessed\"] * 3\n",
    "df_results = df_results[[\"dataset\", \"model\", \"accuracy\", \"micro_f1\", \"macro_f1\"]]\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
